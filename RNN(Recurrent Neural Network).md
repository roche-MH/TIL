# RNN(Recurrent Neural Network)



일반 신경망(FFNets)

개별 데이터를 독립적으로 학습



순환신경망

시계열 데이터 학습에 적합

![image-20200210163529178](C:\Users\Student\Desktop\typora\image\image-20200210163529178.png)

은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력과 은닉층 노드의 다음 계산의 입력으로 보냄

RNN은 sequence data를 처리하는 모델이다. sequence는 순서대로 처리해야 하는 것을 뜻하고, 이런 데이터에는 음성인식, 자연어처리 등이 포함된다. 자연어의 경우 단어 하나만 안다고 해서 처리될 수 없고, 앞뒤 문맥을 함께 이해해야 해석이 가능하다.



RNN에서는 노드를 셀 이라고 하고 이전의 값을 기억하려고 하는 일종의 메모리 역할 수행

![image-20200210163921934](C:\Users\Student\Desktop\typora\image\image-20200210163921934.png)

A에서 나온 화살표가 다시 A로 들어간다. 프로그래밍에서는 이런 걸 재진입(re-enterence) 또는 재귀(recursion)라고 부른다.



RNN은 일반적으로 step을 거칠 때마다 어떤 결과를 예측하게 된다. 그리고, 이런 예측 값을 앞에서 배웠던것처럼 y라고 부른다. y = wx+b 라고 생각하면 된다. 



![image-20200210184949543](C:\Users\Student\Desktop\typora\image\image-20200210184949543.png)

공식으로 표현하면 위와 같이 된다. 이전 단계에서의 상태 값과 입력 벡터로 계산하면 새로운 상태 값이 만들어진다. 코드로 표현하면 아래와 같이 된다.  여기서 노드 갯수는 layer에 포함된 노드(그림에서 초록색으로 표시된 RNN) 갯수를 말한다.



```python
for _ in range(노드 갯수):
    현재상태 = W에 대한 함수(이전상태, 입력벡터)
```



![image-20200210185157224](C:\Users\Student\Desktop\typora\image\image-20200210185157224.png)

바닐라는 아무것도 첨가하지 않은 처음 상태의 아이스크림을 의미한다. 여기서 초코나 딸기 시럽을 얹고 땅콩 가루를 뿌리는 등의 옵션을 추가하면 맛이 더 좋아진다. 바닐라는 아무것도 가공하지 않은 처음 형태로, 바닐라 RNN은 가장 단순한 형태의 RNN 모델을 뜻한다.

hidden layer 마다 각각의 출력이 있다.

![image-20200210165000888](C:\Users\Student\Desktop\typora\image\image-20200210165000888.png)



![image-20200210185350663](C:\Users\Student\Desktop\typora\image\image-20200210185350663.png)

### one-to-one 은 가장 단순한 형태로 1대1기반의 모델이며 바닐라 RNN을 가리킨다.

![image-20200210185437047](C:\Users\Student\Desktop\typora\image\image-20200210185437047.png)

### one-to-many 은 1대다 기반의 모델로 이미지에 대해 설명을 붙일때 사용한다. 한장의 그림에 대해 "소년이 사과를 고르고 있다."처럼 여러개의 단어 형태로 표현될수 있다.

![image-20200210185541847](C:\Users\Student\Desktop\typora\image\image-20200210185541847.png)

### many-to-one는 다대1의 형태의 모델로 여러개의 입력에 대해 하나의 결과를 만들어 준다. 우리가 하는 말을 통해 우리의 심리 상태를 "안정", "불안", "공포" 등의 한 단어로 결과를 예측 할때 사용된다. Sentiment는 감정을 의미한다.

![image-20200210185715701](C:\Users\Student\Desktop\typora\image\image-20200210185715701.png)

### many-to-many 형태의 모델로 기계 번역에서 사용된다. 여러 개의 단어로 구성된 문장을 입력으로 받아서 여러 개의 단어로 구성된 문장을 반환한다. 구글 번역기, 파파고 등이 이에 해당한다.

![image-20200210185812694](C:\Users\Student\Desktop\typora\image\image-20200210185812694.png)

### many-to-many 다대다 모델의 또 다른 형태다. 동영상 같은 경우는 여러개의 이미지 프레임에 대해 여러개의 설명이나 번역 형태로 결과를 반환하게 된다.



# LSTM(Long Short Term Memory Networks)

예측하는데 필요한 문맥이 가까이 있고 많지 않다면 RNN은 이를 학습가능 정보를 필요로 하는 시점과, 필요한 정보가 멀리 떨어져있다면 잘 예측할수 없음, RNN의 히든 state에 cell-state를 추가 하여

state가 오래 경과하더라도 그라디언트가 비교적 전파가 잘 되도록 함

![image-20200210190230550](C:\Users\Student\Desktop\typora\image\image-20200210190230550.png)

LSTM은 셀 스테이트에 신중하게 정제된 구조를 가진 게이트라는 요소를 활용하여 정보를 더하거나 제거하는 기능을 가지고 있다.

게이트 들은 선택적으로 정보들이 흘러들어갈 수 있도록 만드는 장치 이다.  이들은 시그모이드 뉴럴 넷와 점단위 곱하기 연산으로 이루어져있다.

![image-20200210190533045](C:\Users\Student\Desktop\typora\image\image-20200210190533045.png)

시그모이드 레이어는 0 혹은 1 의 값을 출력한다. 그리고 각 구성요소가 얼마만큼의 영향을 주게 될지를 결정해주는 역할을 합니다. 0 이라는 값을 가지게 된다면, 해당 구성요소가 미래의 결과에 아무런 영향을 주지 않도록 만든다. 반면에 1 이라는 값은 해당 구성요소가 확실히 미래의 예측결과에 영향을 주도록 데이터가 흘러가게 만든다.

