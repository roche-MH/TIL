{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 가 많아지면 예측도가 좋아진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H(x1,x2,x3) = x1w1 + x2w2 + x3w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5 samples\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 46ms/sample - loss: 18546.7344\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 5821.3174\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 1832.5706\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 582.3069\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 190.4115\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 67.5696\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 29.0614\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 16.9874\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 13.1991\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 12.0079\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.6308\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.5089\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.4669\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.4500\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.4410\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.4344\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.4286\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.4231\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.4176\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.4122\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.4067\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.4013\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3959\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3905\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3851\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3797\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3742\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3688\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3635\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3580\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 997us/sample - loss: 11.3526\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.3472\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3419\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3365\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3311\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3256\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3203\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3149\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3095\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.3042\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2988\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2935\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2881\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2827\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2774\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2720\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 997us/sample - loss: 11.2666\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2613\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2560\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2506\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2453\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.2399\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2346\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.2293\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 997us/sample - loss: 11.2239\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.2186\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 997us/sample - loss: 11.2133\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.2080\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.2027\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1973\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1920\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1867\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1814\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.1761\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.1708\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.1655\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1602\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1549\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1496\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/sample - loss: 11.1443\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1391\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1338\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1285\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.1232\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.1180\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.1127\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1075\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.1022\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0969\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0916\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.0864\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.0811\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0759\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0706\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.0654\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0602\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0549\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0497\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.0444\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 11.0392\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0340\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0288\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 11.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.0183\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.0131\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 11.0079\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 997us/sample - loss: 11.0027\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/sample - loss: 10.9975\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 10.9923\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 10.9871\n",
      "[[166.67061]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = [[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]]\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(units=1, input_dim=3))  # input_dim=3 gives multi-variable regression\n",
    "tf.model.add(tf.keras.layers.Activation('linear'))  # this line can be omitted, as linear activation is default\n",
    "# advanced reading https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
    "\n",
    "tf.model.compile(loss='mse', optimizer=tf.keras.optimizers.SGD(lr=1e-5))\n",
    "tf.model.summary()\n",
    "history = tf.model.fit(x_data, y_data, epochs=100)\n",
    "\n",
    "y_predict = tf.model.predict(np.array([[72., 93., 90.]]))\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e199d0a048>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('../data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(x_data, \"\\nx_data shape:\", x_data.shape)\n",
    "print(y_data, \"\\ny_data shape:\", y_data.shape)\n",
    "\n",
    "# data output\n",
    "'''\n",
    "[[ 73.  80.  75.]\n",
    " [ 93.  88.  93.]\n",
    " ...\n",
    " [ 76.  83.  71.]\n",
    " [ 96.  93.  95.]] \n",
    "x_data shape: (25, 3)\n",
    "[[152.]\n",
    " [185.]\n",
    " ...\n",
    " [149.]\n",
    " [192.]] \n",
    "y_data shape: (25, 1)\n",
    "'''\n",
    "tf.model = tf.keras.Sequential()\n",
    "# activation function doesn't have to be added as a separate layer. Add it as an argument of Dense() layer\n",
    "tf.model.add(tf.keras.layers.Dense(units=1, input_dim=3, activation='linear'))\n",
    "# tf.model.add(tf.keras.layers.Activation('linear'))\n",
    "tf.model.summary()\n",
    "\n",
    "tf.model.compile(loss='mse', optimizer=tf.keras.optimizers.SGD(lr=1e-5))\n",
    "history = tf.model.fit(x_data, y_data, epochs=2000)\n",
    "\n",
    "# Ask my score\n",
    "print(\"Your score will be \", tf.model.predict([[100, 70, 101]]))\n",
    "print(\"Other scores will be \", tf.model.predict([[60, 70, 110], [90, 100, 80]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
